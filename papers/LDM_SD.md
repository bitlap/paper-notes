# 使用潜在扩散模型进行高分辨率图像合（LDM/SD）

High-Resolution Image Synthesis with Latent Diffusion Models - 使用腾讯元宝翻译整理

## 1. 引言 (Introduction)

### 背景与挑战
- 图像合成领域进展显著，但计算需求巨大，尤其是高分辨率合成。
- 扩散模型 (DM) 在多个任务上达到SOTA，但存在严重瓶颈：
  - **训练成本极高**：需数百GPU天。
  - **推理成本极高**：生成速度慢。
- 本质问题：DM将过多计算资源用于建模难以感知的细节。

### 解决方案：转向潜在空间
- **关键洞察**：图像形成过程可分为：
  1.  **感知压缩**：去除高频细节。
  2.  **语义压缩**：学习语义和概念组合。
- **LDM核心思想**：在感知等效的低维潜在空间中训练扩散模型。
- **方法**：
  1.  使用预训练的自编码器 (`ℰ`, `𝒟`) 将图像压缩到潜在空间。
  2.  在潜在空间 `z = ℰ(x)` 中训练扩散模型。
- **优势**：
  - 大幅降低计算复杂度。
  - 避免过度压缩，保持高质量重建。
  - 潜在空间可复用于多种任务。

### 主要贡献
1.  **可扩展性**：比纯Transformer方法更优雅地扩展到高维数据。
2.  **高效高性能**：在多任务上达到competitive性能，显著降低计算成本。
3.  **简化训练**：无需精细权衡重建与生成能力。
4.  **高分辨率生成**：可卷积方式生成 >1024² 像素的一致图像。
5.  **灵活条件机制**：基于交叉注意力，支持多模态（文本、布局等）训练。
6.  **开源模型**：发布预训练模型，促进后续研究。

## 3. 方法 (Method)

### 3.1 感知图像压缩
- **目标**：学习一个低维、感知等效的潜在表示空间。
- **模型**：基于自编码器架构。
  - 编码器 `ℰ`: `x -> z` (下采样因子 `f = H/h = W/w`)。
  - 解码器 `𝒟`: `z -> x̃`。
- **训练目标**：结合感知损失和对抗损失，确保重建质量高且逼真。
- **正则化**：两种方案避免潜在空间方差过大：
  - **KL正则化**：轻微KL散度惩罚，类似VAE。
  - **VQ正则化**：使用向量量化层，类似VQGAN。
- **优势**：使用相对温和的压缩率 (`f=4,8`)，即可实现高质量重建，为后续扩散模型提供良好基础。

### 3.2 潜在扩散模型 (LDM)
- **动机**：潜在空间更适用于似然模型，可聚焦语义信息，计算效率高。
- **损失函数**：将扩散损失迁移到潜在空间：
  $L_{LDM} := \mathbb{E}_{\mathcal{E}(x), \epsilon, t} \left[ \| \epsilon - \epsilon_\theta(z_t, t) \|_2^2 \right]$
- **网络架构**：使用时间条件UNet作为去噪网络 `ϵθ` 的骨干。
- **流程**：
  - 训练：通过编码器 `ℰ` 高效获取噪声潜在 `z_t`。
  - 采样：从 `p(z)` 采样，通过解码器 `𝒟` 一次传递即可解码为图像。

### 3.3 条件机制
- **目标**：学习条件分布 `p(z|y)`，控制生成过程（`y` 可为文本、语义图等）。
- **核心创新**：在UNet中引入**交叉注意力层**实现条件控制。
- **实现**：
  1.  条件信息 `y` 通过领域专家编码器 `τθ` (如Transformer) 编码为中间表示 `τθ(y)`。
  2.  通过交叉注意力将 `τθ(y)` 注入到UNet的中间层：
      `Attention(Q, K, V) = softmax(QK^T / √d) · V`
      - `Q = W_Q · φ_i(z_t)` (UNet特征)
      - `K = W_K · τ_θ(y)`, `V = W_V · τ_θ(y)` (条件信息)
- **训练目标**：
  $L_{LDM} := \mathbb{E}_{\mathcal{E}(x), y, \epsilon, t} \left[ \| \epsilon - \epsilon_\theta(z_t, t, \tau_\theta(y)) \|_2^2 \right]$
- **优势**：条件机制灵活通用，支持多种模态。

## 4. 实验 (Experiments)

### 4.1 感知压缩权衡
- **实验**：比较不同下采样因子 `f` (LDM-1 到 LDM-32) 的性能。
- **发现**：
  - `f` 太小 (LDM-1,2)：训练慢。
  - `f` 太大 (LDM-16,32)：质量上限低。
  - `f=4,8`：在效率和质量间取得最佳平衡。
- **结论**：LDM-4/8 是理想选择。

### 4.2 图像生成（无条件）
- **数据集**：CelebA-HQ, FFHQ, LSUN-Churches, LSUN-Bedrooms。
- **结果**：
  - **CelebA-HQ**：FID=5.11 (新SOTA)，超越以往基于似然模型和GAN。
  - **其他数据集**：在FID、Precision、Recall上均达到competitive或SOTA性能。
  - **效率**：推理速度远超像素空间扩散模型。
- **样本质量**：生成样本视觉质量高（见图4）。

### 4.3 条件图像生成

#### 4.3.1 Transformer编码器应用
- **文本到图像**：
  - 在LAION上训练1.45B参数模型。
  - 可生成符合复杂文本提示的高质量图像（图5,8）。
  - 在MS-COCO上定量评估，媲美或超越同期AR、GAN和扩散模型。
  - 使用无分类器引导后，质量大幅提升。
- **布局到图像**：在COCO和OpenImages上训练，可依据边界框生成图像，性能优越（表9，图16）。
- **类别条件ImageNet**：
  - 性能超越ADM等模型。
  - 参数量和计算需求显著降低（表3,10）。

#### 4.3.2 超越训练分辨率的卷积采样
- **现象**：在256²上训练的模型，可通过卷积方式生成 >256² (如512x1024) 的高分辨率一致图像。
- **应用**：用于语义合成、超分辨率、修复等任务。
- **关键**：调节潜在空间的信号噪声比(SNR)至关重要。

### 4.4 超分辨率 (SR)
- **方法**：以LR图像为条件，通过Concatenation输入UNet。
- **结果**：
  - 在ImageNet上性能与SR3等模型竞争（FID更优，IS稍逊）。
  - 用户研究表明人类更喜欢LDM-SR的结果。
- **通用SR模型 (LDM-BSR)**：通过多样化退化训练，能泛化到真实世界图像，实用性强。

### 4.5 图像修复 (Inpainting)
- **设置**：遵循LaMa协议，在Places数据集上评估。
- **效率**：相比像素扩散模型，**训练和采样加速≥2.7倍**，FID提升≥1.6倍。
- **性能**：FID指标优于LaMa，生成多样性更丰富（图21）。
- **用户研究**：人类评估者更偏好LDM的结果。
- **大模型微调**：大模型经微调后，达到修复任务新SOTA（图11,22）。
