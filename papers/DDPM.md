# 去噪扩散概率模型 （DDPM）

Denoising Diffusion Probabilistic Models - 使用腾讯元宝翻译整理

## 2. 详细背景

想象一下，你有一张清晰的数码照片（这就是原始数据 $\mathbf{x}_0$）。

### 1. 前向过程（Forward Process）：逐步加噪
论文中把这个过程叫做 $q$。这个过程是**固定的**，不需要学习。

*   **它做了什么？** 这个过程就像你拿着一杯清水，然后**一步一步地**滴入墨水。每一步都滴入一小滴（对应一个很小的方差 $\beta_t$），并搅拌均匀。
*   **经过很多很多步（比如1000步）后**，这杯清水就变成了一整杯纯黑的墨水，你完全看不出它原来是一杯清水。同样，一张清晰的图片 $\mathbf{x}_0$，经过这个过程，就变成了一个**完全随机的噪声图片 $\mathbf{x}_T$**，看不出任何原图的信息。
*   **数学上**，这个过程被定义为一个**马尔可夫链**（意思是每一步的状态只依赖于前一步的状态）。每一步加的噪声都是**高斯噪声（Gaussian noise）**，也就是一种非常常见、规律的随机噪声。
*   **一个重要技巧**：因为每一步加的噪声都很小且是高斯分布，作者推导出了一个“捷径”公式（公式4）。这意味着我们不需要真的一步一步地加噪1000次才能得到第100步的噪声图。我们可以**直接通过原始图片 $\mathbf{x}_0$ 计算出任何一步 $t$ 的噪声图片 $\mathbf{x}_t$**，这大大加快了训练速度。

**打个比方：** 前向过程就像一个预设好的“毁灭程序”，它有条不紊地、可预测地将任何一张图片摧毁成一片毫无意义的噪声。

### 2. 反向过程（Reverse Process）：学习去噪
论文中把这个过程叫做 $p_\theta$。这个过程是**需要学习的**，也是模型的核心。

*   **目标是什么？** 我们的目标是学习一个反向过程，它能从一杯纯黑的墨水（噪声 $\mathbf{x}_T$）开始，**一步一步地“倒放”前向过程**，最终还原出一杯清水（清晰的图片 $\mathbf{x}_0$）。
*   **如何学习？** 既然前向过程是固定的（我们知道怎么把图变噪声），我们就可以利用它来训练模型。具体方法是：
    1.  随便拿一张训练图片 $\mathbf{x}_0$。
    2.  随机选择一个时间步 $t$（比如第500步）。
    3.  利用前面的“捷径”，直接计算出加了 $t$ 步噪声后的图片 $\mathbf{x}_t$。
    4.  现在，任务来了：我们让神经网络（参数为 $\theta$）看着这个噪声图 $\mathbf{x}_t$，去预测**如何从这一步回到上一步**，即预测 $\mathbf{x}_{t-1}$。
    5.  因为前向过程也是已知的，我们知道真正的、从 $\mathbf{x}_t$ 回退到 $\mathbf{x}_{t-1}$ 应该是什么样子（公式6和7）。这样我们就可以计算神经网络的预测和真实值之间的差异（损失函数），并通过这个误差来调整神经网络参数（$\theta$），让它下次预测得更准。

*   **神经网络的任务**：在每一步 $t$，神经网络需要预测反向过程的**均值（mean, $\boldsymbol{\mu}_\theta$）** 和**方差（variance, $\boldsymbol{\Sigma}_\theta$）**。简单理解，均值是告诉我们应该往哪个方向去噪，方差则表示了这一步的不确定性有多大。

**打个比方：** 反向过程就像一个“修复大师”。我们通过给他看各种“被毁坏到不同程度”（$\mathbf{x}_t$）的文物以及“正确的修复步骤”（前向过程的逆），来训练他。训练完成后，给他一个全新的、完全被毁坏的文物（纯噪声），他就能自己一步步地把它完美修复出来。

### 3. 训练目标：Variational Bound
论文用了一个叫做**变分下界（variational bound）** 的概念来推导出最终的损失函数 $L$（公式3和5）。这个东西听起来很高大上，但你可以这样理解：

*   它的目的就是为了**最大化生成真实图片 $\mathbf{x}_0$ 的概率**。
*   通过一系列数学变换，这个复杂的目标被分解成了几个简单的部分（公式5中的 $L_T$, $L_{t-1}$, $L_0$）：
    *   $L_T$: 让最后的噪声 $\mathbf{x}_T$ 尽量接近标准高斯分布（一堆纯噪声）。在我们的设定中，这部分几乎是零，是个常数。
    *   $L_{t-1}$: 这是最主要的部分！它让神经网络学习的反向过程 $p_\theta$ 尽可能地去匹配前向过程的逆 $q$（就是我们之前说的，让网络预测的去噪步骤和真实的去噪步骤保持一致）。
    *   $L_0$: 最后一步，将 latent 变量 $\mathbf{x}_1$ 解码回最终的图片像素 $\mathbf{x}_0$。

**通俗总结：** 整个训练过程就是在教神经网络如何一步步地、“精益求精”地完成“去噪”这个任务。每一步都要求它做出的去噪动作尽可能接近理论上完美的去噪动作。

## 3. 扩散模型与去噪自编码器

本节揭示了扩散模型与去噪得分匹配之间的深刻联系，并提出了关键的参数化方法和简化目标。

### 3.1 前向过程与 $L_T$
*   **核心内容**：将前向过程的方差 $\beta_t$ 固定为常数，而非可学习参数。
*   **通俗解读**：前向过程是预设好的“毁灭程序”，其规则固定。因此，最终噪声分布 $q(\mathbf{x}_T | \mathbf{x}_0)$ 与先验分布 $p(\mathbf{x}_T)$ 之间的差异 $L_T$ 是一个常数。
*   **影响**：在训练时，常数 $L_T$ 可以被忽略，简化了优化目标。

### 3.2 反向过程与 $L_{1:T-1}$ (核心创新)
本节是论文最重要的贡献，提出了关键的参数化方法。

**1. 反向过程方差的选择**
*   **选择**：将反向过程的方差 $\boldsymbol{\Sigma}_\theta(\mathbf{x}_t, t)$ 设置为固定值（$\sigma_t^2 = \beta_t$ 或 $\sigma_t^2 = \tilde{\beta}_t$），而非可学习。
*   **解读**：学习方差会导致训练不稳定且对效果提升有限。固定方差后，神经网络只需专注于学习更重要的**均值**。

**2. 重新参数化：从预测均值到预测噪声**
*   **原始方法**：让神经网络 $\boldsymbol{\mu}_\theta$ 直接预测前向过程后验的均值 $\tilde{\boldsymbol{\mu}}_t$。
*   **重新参数化**：通过数学推导，将真实均值 $\tilde{\boldsymbol{\mu}}_t$ 重写为：
    $\tilde{\boldsymbol{\mu}}_t = \frac{1}{\sqrt{\alpha_t}} \left( \mathbf{x}_t - \frac{\beta_t}{\sqrt{1 - \bar{\alpha}_t}} \boldsymbol{\epsilon} \right)$
    这表明均值可以通过从当前噪声图 $\mathbf{x}_t$ 中减去原始噪声 $\boldsymbol{\epsilon}$ 来计算。
*   **关键创新**：改变神经网络的任务！不让它直接预测复杂的均值，而是让它去预测在前向过程中添加的**噪声 $\boldsymbol{\epsilon}$**。新的均值参数化为：
    $\boldsymbol{\mu}_\theta(\mathbf{x}_t, t) = \frac{1}{\sqrt{\alpha_t}} \left( \mathbf{x}_t - \frac{\beta_t}{\sqrt{1 - \bar{\alpha}_t}} \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t) \right)$
    其中 $\boldsymbol{\epsilon}_\theta$ 是一个预测噪声的新网络。
*   **带来的简化**：代入损失函数后，复杂的损失项 $L_{t-1}$ 简化为：
    $L_{t-1} \propto \mathbb{E} \left[ \| \boldsymbol{\epsilon} - \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t) \|^2 \right]$
    **训练目标变为最小化真实噪声与预测噪声之间的均方误差**。
*   **与去噪得分匹配的等价性**：此目标函数“类似于去噪得分匹配”。预测噪声 $\boldsymbol{\epsilon}_\theta$ 在数学上等价于学习数据对数概率的梯度（得分）。采样过程则类似于**退火的朗之万动力学**，由 $\boldsymbol{\epsilon}_\theta$ 指导采样方向。

**3. 其他预测目标**
*   尝试预测原始图像 $\mathbf{x}_0$ 会导致更差的样本质量。预测噪声被证明是最有效的目标。

### 3.3 数据缩放、反向解码器与 $L_0$
*   **数据缩放**：将图像像素从 `[0, 255]` 线性缩放至 `[-1, 1]`，以匹配高斯先验分布 $\mathcal{N}(\mathbf{0}, \mathbf{I})$。
*   **离散解码器**：设计了一个简单的解码器（公式13），通过对高斯PDF在离散值bins内积分来计算 $p_\theta(\mathbf{x}_0 | \mathbf{x}_1)$，确保为离散图像提供有效的无损码长。

### 3.4 简化的训练目标 ($L_{\text{simple}}$)
*   **最终目标**：基于预测噪声的参数化，提出了简化目标：
    $L_{\text{simple}}(\theta) := \mathbb{E}_{t, \mathbf{x}_0, \boldsymbol{\epsilon}} \left[ \| \boldsymbol{\epsilon} - \boldsymbol{\epsilon}_\theta( \sqrt{\bar{\alpha}_t} \mathbf{x}_0 + \sqrt{1 - \bar{\alpha}_t} \boldsymbol{\epsilon}, t ) \|^2 \right]$
*   **与原始目标的区别**：
    1.  **忽略权重项**：$L_{\text{simple}}$ 丢弃了原始损失中的加权系数 $\frac{\beta_t^2}{2\sigma_t^2 \alpha_t (1 - \bar{\alpha}_t)}$。
    2.  **动机与效果**：该权重项会给噪声较少的简单任务（小 $t$）赋予高权重。去除权重相当于**重新平衡了损失**，让模型更专注于噪声多的困难任务（大 $t$）。实验表明，虽然 $L_{\text{simple}}$ 对应的对数似然稍差，但它能**产生质量高得多的样本**。


## 4. 实验 (Experiments) - 样本质量详解

本节通过大量实验验证了DDPM的卓越性能，并进行了深入的消融研究。

### 4.1 样本质量 (Sample Quality)

**实验设置**:
*   **总时间步 (`T`)**: 固定为 `1000`，与前人工作对比公平。
*   **噪声调度 (`β_t`)**: 线性 schedule (`β₁=1e-4` 到 `β_T=0.02`)，确保最终潜变量 `x_T` 近乎纯噪声。
*   **模型架构**: 基于 **U-Net** 与 **PixelCNN++** 组件，加入 **自注意力机制**。时间步 `t` 通过 **正弦位置编码** 注入。

**主要结果**:
*   **CIFAR10 (无条件生成)**:
    *   **Inception Score (IS)**: **9.46** → 超越了当时许多模型（包括部分条件生成模型），表明生成样本多样且清晰。
    *   **Fréchet Inception Distance (FID)**: **3.17** → 达到了**最先进 (SOTA)** 水平，甚至优于BigGAN等著名模型，证明生成分布与真实分布极其接近。
    *   **负对数似然 (NLL)**: ~3.75 bits/dim → 并非最优，引出了模型是**优秀有损压缩器**的结论。
*   **高分辨率生成 (256x256)**:
    *   **视觉质量**: 在LSUN和CelebA-HQ上生成的样本视觉上与 **ProgressiveGAN** 质量相当（见图1,3,4）。
    *   **FID分数**: LSUN Bedroom上达到 **4.90** (大模型) 和 **6.36** (小模型)，证明了扩散模型在高分辨率领域的潜力。

**关键观察**:
*   使用简化目标 `L_simple` 训练的模型，其**样本质量远超**使用原始变分下界 `L` 的模型，尽管前者似然稍差。
*   训练/测试NLL差距极小，表明**无过拟合**。

### 4.2 消融实验 (Ablation Study)

本实验验证了第3节核心设计的有效性（Table 2）:

**1. 预测目标 (Prediction Target)**:
*   **预测均值 (`μ`)**: 基线方法，效果一般（FID 13.22）。
*   **预测噪声 (`ϵ`) + `L_simple`**: **最佳组合** (IS 9.46, FID 3.17)。证明了“预测噪声”参数化的优越性。

**2. 方差处理 (Variance)**:
*   **固定方差**: 效果更好，训练稳定。
*   **学习方差**: 导致训练不稳定和差的结果。

**3. 目标函数 (Objective)**:
*   `L_simple` ** > ** `L`。简化目标通过让模型专注于高噪声水平的困难去噪任务，显著提升了样本质量。

### 4.3 渐进编码与生成 (Progressive Coding)

解释了高质量有损压缩与一般无损压缩之间的矛盾。

*   **速率-失真分析**: 变分下界 `L` 的大部分比特（>1.5 bits/dim）用于编码**人眼难以察觉的细微失真**（`L₀` 约 1.97 bits/dim, RMSE=0.95）。
*   **渐进有损解码**: 在解码的任何中间步 `t`，均可根据 `x_t` 得到有损重建 `x̂₀`。Figure 5 显示，**初期少量比特大幅降低失真（重建结构），后期比特修复细节**。
*   **渐进生成**: 采样过程是**从粗到细**的（Figure 6）。先生成轮廓和语义，再细化纹理。
*   **与自回归模型的联系**: 作者指出，扩散模型是自回归模型的**广义形式**。它采用了一种基于**噪声水平**而非像素位置的、更适用于图像的“比特排序”策略。

### 4.4 插值 (Interpolation)

*   **方法**: 在潜空间 `x_t`（如 `t=500`）中对源图像的噪声版本进行线性插值，然后解码。
*   **结果**: 插值结果平滑且语义连贯（Figure 8），能融合高级属性（姿态、发型等），证明了潜空间的结构化特性。
